---
title: Chap6. Linear Model Selection and Regularization
excerpt: ISL 
toc: true
toc_sticky: true

author_profile: false

date: 2021-09-07 12:30:00 -0000
categories: 
  - ISL 
tags:
  - Machine Learning
---

<br>

이 장에서는 선형모형의 최소제곱법을 다른 적합법으로 대체해서 모델을 개선시키는 방법에 대해 알아본다. <br>
최소제곱법을 사용하지 않고 다른 방법을 사용하려는 이유는 무엇일까? <br>
이유는 다른 방법들을 사용했을 때 더 나은 예측 정확도와 모델 해석력을 제공할 수 있기 때문이다.

- 예측 정확도 : 반응변수와 설명변수들 사이의 상관관계가 거의 선형인 경우 최소제곱 추정치들은 편향이 적을 것이다. low-dimension 일 때는 낮은 분산을 가지는 경향이 있고, test set에 대해서도 좋은 성능을 낼 것이다. 그렇지만 n이 p보다 많이 크지 않으면 최소제곱법의 변동이 커지고 과적합 문제가 생긴다. high-dimension일 때는 더이상 unique 한 최소제곱추정량이 존재하지 않는다. 이 때는 계수들을 shrinkage 하는 방법을 이용한다.

- 모델 해석력 : 다중회귀모형에서 사용되는 변수들은 반응변수와 관련 없는 경우도 많다. 이러한 변수들을 제거하여 모델을 간소화시키기 위해 변수에 대응하는 계수 추정치를 0으로 만들어준다. 최소제곱법으로는 계수 추정치를 0으로 만들 수 없으므로 다른 방법을 이용해야 한다.

<br>

이 장에서 배우게 될 최소제곱법의 대안들은 다음과 같이 크게 세 가지가 있다.

- subset selection : $p$개의 설명변수 중에서 반응변수와 관련이 있다고 생각하는 부분집합을 찾아낸다. 이 부분집합만으로 최소제곱법을 적용하여 모델을 만든다.

- shrinkage : $p$개의 설명변수 모두를 포함하며 모델을 적합하긴 하지만 추정된 계수를 최소제곱 추정치와 비교해 0으로 수축시킨다. 이 방법은 분산을 줄여준다.

- Dimension Reduction : $p$개의 설명변수를 $M$차원 부분공간으로 투영하는 것이다. 이 공간은 $M$개 다른 선형결합 또는 투영을 계산함으로써 얻어진다. 이 $M$개의 설명변수로 선형회귀모형을 적합한다.

<br>
<br>

# 1. 부분집합 선택

- best subset 선택
- 
$p$개 설명변수들의 모든 가능합 조합 각각에 대해 최소제곱법을 이용해 모델을 적합하고, 이 모델들 중에 최고의 모델을 찾는다. <br>
$2^p$개의 모델을 적합해야 하므로 계산량이 상당히 많다.

- forward selection

- backward elimination

- stepwise selection













