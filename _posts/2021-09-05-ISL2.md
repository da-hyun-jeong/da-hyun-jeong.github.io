---
title: 2. Statistical Learning
excerpt: 통계학습 
toc: true
toc_sticky: true

author_profile: false

date: 2021-09-04 21:30:00 -0000
categories: 
  - ISL 
tags:
  - Machine Learning
---

<br>

# 1. Statistical Learning 이란 ? 

$p$개의 입력변수 $X$와 출력변수 $Y$ 사이에 어떤 상관관계가 있다고 가정하고 모델을 세운다.

$$  Y = f(X) + \epsilon $$

여기서 오차항 $\epsilon$은 $X$와 독립이고 평균이 0이다.

<br>

> $f$를 추정하는 이유

1. 예측

대부분의 경우 입력변수 $X$는 쉽게 얻을 수 있지만 출력변수 $Y$는 쉽게 얻을 수 없다.
예측식은 다음과 같다. 

$$ \hat{Y} =  \hat{f}(X) $$

결정모형을 제외한다면 $\hat{f}$는 블랙박스로 취급된다.

예측오차는 reducible error와 irreducible error가 있다. <br>
$f$가 아무리 정확하더라도 정의에 의해 $\epsilon$은 입력변수 $X$로 예측할 수 없으므로 축소불가능 오차는 생길 수 밖에 없다. <br>
따라서 모든 방법론의 목적은 축소가능 오차를 최소로 하는 것이 목적이다. <br>

<br>

2. 추론

관심변수 $Y$에 어떤 입력변수들이 영향을 미치는지 알아내는 데 관심이 있다.
즉 $X$와 $Y$의 관계를 알아내는 것이 목적이다.
관련된 질문들은 아래와 같은 것들이 있다.

- 어떤 설명변수들이 반응변수와 관련이 있는가? 
- 설명변수와 반응변수의 상관관계는 어떠한가?

목적에 따라 설명력이 좋은 모델, 예측력이 높은 모델을 선택할 수 있다.

<br>

> 어떻게 $f$를 추정하는가?

우리의 목적은 선형, 비선형 기법들을 training dataf에 적용하여 $f$를 추정하는 것이다. <br>
$f$를 추정하기 위해 대부분의 방법론들은 모수적 또는 비모수적 방법으로 나눌 수 있다.

<br>

1. 모수적 방법


모수적 방법은 $f$의 형태를 가정하고 training data를 이용해 훈련시키는 방법이다. <br>
여기서는 $f$를 추정하는 문제가 파라미터들을 추정하는 문제로 축소되므로 비교적 단순해진다. <br>
그러나 실제 $f$와 맞지 않는 경우가 있을 수 있다. <br>
좀 더 유연한 모델을 사용한다고 하더라도 과적합의 문제가 있다.

<br>

2. 비모수적 방법

비모수적 방법은 $f$의 형태를 가정하지 않고 가능하면 데이터와 가까운 예측식을 얻고자 한다. <br>
모수적 방법은 방법론에 따라 함수 형태가 많이 바뀔 수 있지만 비모수적 방법은 그렇지 않다. <br>
하지만 중요한 단점은 추정해야 할 파라미터 수가 늘어나므로 표본크기가 커야 한다. <br>
이 방법도 과적합 문제가 발생할 수 있다.

<br>

> 모델의 예측력과 해석력 사이의 trade-off

주 관심이 추론이라면 해석력이 좋은 제한적인 모델이 선호된다. <br>
넓은 범위에서 예측력이 높은 모델을 원한다면 유연한 모델을 사용하는 것이 좋다. <br>
예를 들어 lasso는 계수를 추정하는데 제한이 있으므로 제한적이고 유연성이 떨어진다. <br>
배깅, 부스팅, SVM과 같은 비선형 커널을 이용하는 방법론들은 해석이 어렵지만 유연한 기법들이다. <br>
실제 모델링을 했을 때 이러한 직관과 반대되는 상황이 있다면 과적합과 관련이 있을 수 있다.

<br>

> 지도학습과 비지도학습 

분석의 방향을 지도할 수 있는 반응변수가 있는지 없는지에 따라 달라진다고 생각할 수 있다. <br>

1. 지도학습(supervised learning)
- 설명변수와 반응변수에 대한 모든 정보가 있다.
- 선형모형, 로지스틱 모형, 일반화가법모형(GAM), 부스팅, SVM 등
- 설명변수와 반응변수 간의 상관관계, 더 정확한 예측

<br>

2. 비지도학습(unsupervised learning)
- 설명변수들에 대한 정보만 있다. 
- 군집분석(clustering)
- 변수들 간 또는 관측치들 간의 상관관계
  
<br>

3. 준지도학습(semi-supervised learning)

$n$개의 관측치에 대해 $m<n$개의 관측치는 설명변수, 반응변수에 대한 완전한 정보가 있지만 $n-m$개의 관측치에 대해서는 설명변수에 대한 정보만 있는 경우 준지도학습 문제라고 한다.

<br>

> 회귀와 분류

반응변수가 양적변수이면 회귀 문제이고, 반응변수가 질적변수이면 분류 문제이다. <br>
이것이 명확하게 분류되지는 않는다.

<br>
<br>

# 2. 모델의 정확도 평가

<br>

모든 자료에 대해 어떤 한 방법이 다른 방법들보다 지배적으로 나은 경우는 없다. <br>
따라서 여러가지 방법론들을 이해하는 것이 중요하다. <br>
주어진 자료에 대해 최고의 결과를 제공해주는 방법론을 찾아내는 것은 중요하고 매우 어렵다.

<br>

>적합의 품질 측정 


1. $\; training  \; MSE$

주어진 자료에 대한 내가 세운 모델의 성능을 평가하기 위해서는 예측값이 실제값을 얼마나 잘 측정했는지를 수량화한 척도가 필요하다. <br>
회귀 문제에서 가장 일반적으로 사용되는 척도는 $MSE$이다.

$$
MSE = \frac{1}{n}\sum_{i=1}^{n}(y_i-\hat{f}(x_i))^2
$$


<br>

2. $\; test  \; MSE$

실제로는 모델이 training data에 대해 얼마나 잘 작동하는지보다 test data에서 예측력이 얼마나 좋은지가 관심이 있다.

$$
Ave(y_0-\hat{f}(x_0))^2
$$

$test  \; MSE$가 가능한 한 작은 모델을 선택하는 것이 좋다 !

<br>

3. $test  \; MSE$ 를 최소로 하는 방법을 어떻게 선택할까?

어떤 경우에는 사용할 수 있는 test data가 있을 수 있지만, 그렇지 않은 경우는 어떻게 할까? <br>
$training \; MSE$를 최소로 하는 방법론을 선택하는 방법을 생각해볼 수 있다. <br>
그러나 $training \; MSE$가 가장 낮은 방법이 $test \; MSE$도 가장 낮게 할 것이라는 보장이 없다.

<br>

<p align="center">
	<img src="https://user-images.githubusercontent.com/86343664/132125971-854e6c37-66db-4e24-8efd-d83d79784161.png">
</p>

<br>

사진을 보면 모델의 유연성이 증가함에 따라 $training \; MSE$는 단조감소하지만 $test \; MSE$는 U-shape를 가진다. <br>
$training \; MSE$는 작지만 $test \; MSE$는 큰 과적합 현상이 나타난 것이다. <br>
어떤 모델을 쓰냐에 상관없이 기본적으로 나타나게 된다.

<br>

$test \; MSE$가 최소가 되는 모델에 대응되는 유연성 수준은 자료에 따라 상당히 달라진다. <br>
이 지점을 추정하는 방법은 대표적으로 교차검증(cross-alidation)이 있다.

<br>

> bias-variance trade-off

$test \; MSE$가 U-shape curve를 보이는 것은 $test \; MSE$가 bias와 variance로 분해했을 때의 trade-off 관계 때문이다. <br>
주어진 $x_0$ 값에 대해 expected $test \; MSE$에 대한 다음의 식이 성립한다.

$$
E(y_0-\hat{f}(x_0))^2 = Var(\hat{f}(x_0)) + [Bias(\hat{f}(x_0))]^2 + Var(\epsilon)
$$

여기서 $E(y_0-\hat{f}(x_0))^2$는 $test \; MSE$의 기댓값으로 모든 test point $x_0$의 값에 대한 평균값이다. <br>
위의 식에 의하면 기대검정오차를 최소화하기 위해서는 $low \; variance$와 $low \; bias$를 동시에 달성하는 방법을 선택해야 한다. <br>

<br>

1. 분산

분산은 다른 training data를 사용해서 추정했을 때 $\hat{f}$이 변동되는 정도를 말한다. <br>
training data가 변하면 $\hat{f}$이 달라지는 것은 분명하지만 이상적으로는 자료가 바뀐다고 해서 추정 결과가 많이 변동되면 안된다. <br>
그러나 분산이 크면 training data의 변화가 작아도 $\hat{f}$은 크게 달라진다.  (데이터가 나올 수 있는 범위가 넓어짐.) <br>
일반적으로 모델의 유연성이 높을수록 분산도 커진다.

<br>

<p align="center">
	<img src="https://user-images.githubusercontent.com/86343664/132125972-295c5a98-7b5d-41a9-a510-23bb5a2325ae.png" width="70%" height="70%"/>
</p>

위에서 보았던 그림이다. <br>
스플라인 곡선은 관측치들을 아주 잘 따라가므로 하나를 변화시키면 추정치가 상당히 변하게 되므로 유연성이 높고 분산이 크다. <br>
선형회귀직선은 어떤 하나의 관측치를 이동해도 위치 변화가 크지 않으므로 유연하지 않고 분산이 낮다.

<br>

2. 편향

편향은 실제 문제를 훨씬 단순한 모델로 근사시킴으로 인해 발생하는 오차이다. <br>
예를 들어 선형회귀는 $Y$와 $X_1, .., X_p$ 사이에 선형관계가 있다고 가정한다. <br>
실제 문제가 이러한 단순한 상관관계를 가질 가능성은 거의 없으므로 $f$를 추정하면 틀림없이 어떤 편향이 발생하게 될 것이다. <br>

<br>

<p align="center">
	<img src="https://user-images.githubusercontent.com/86343664/132125973-c6eb8043-b6f0-4d1f-b00e-8c42448e12f6.png" width="70%" height="70%"/>
</p>

<br>

실제 모델(까만선)은 비선형이므로 아무리 많은 관측치가 있어도 선형회귀로는 정확한 추정을 할 수 없다.

<br>

3. trade-off
   
<p align="center">
	<img src="https://user-images.githubusercontent.com/86343664/132125974-de0b76e1-21ee-41e6-9f92-79127daac647.png">
</p>

<br>

위의 그림은 여러 자료에 대한 $test \; MSE$를 나타낸다. <br>
세 경우 모두 유연성이 증가함에 따라 분산은 증가하고 편향은 감소한다. <br>
하지만, 자료에 따라 최적의 $test \; MSE$를 제공하는 유연성 수준은 상당히 다르다. <br>
이유는 각 자료마다 편향과 분산이 변하는 속도가 다르기 때문이다. 

<br>

편향, 분산, $test \; MSE$ 사이의 관계를 **bias-variance trade-off** 라고 한다. <br>
한 가지에만 집중하는 방법을 찾는 것은 어렵지 않지만 둘 다 낮은 방법을 찾는 것은 어렵다. <br>
따라서 이러한 절충은 가장 중요한 주제 중 하나이다. <br>
또한 실제 $f$가 관측되지 않을 때는 이러한 계산값을 얻는 것이 불가능하지만 항상 염두해두어야 한다.

<br>

> 분류 설정


분류 설정에서는 bias-variance trade-off에 관한 식은 개념은 같으나 살짝 수정된다. <br>
training data $\{(x_1,y_1),...,(x_n,y_n)\}$을 기반으로 $f$를 추정한다고 해보자. <br>
여기서 $y_1,...,y_n$은 질적변수이다. <br>
추정치 $\hat{f}$의 정확도를 수량화하는 가장 일반적인 방법은 $training \; error \;rate$이다.

$$
\frac{1}{n}\sum_{i=1}^{n} I(y_i \neq \hat{y_i})
$$

위 식은 분류기를 훈련시키는 데 사용되었던 데이터를 기반으로 계산되므로 훈련오차율이라고 한다. <br>
test data $(x_0, y_0)$에 대한 $test \; error \;rate$는 다음 식으로 주어진다.

$$
Ave( I(y_0 \neq \hat{y_0}) )
$$

좋은 분류기는 검정오차가 가장 작은 것이다.

<br>

1. 베이즈 분류기(Bayes Classifier)

$test \; error \;rate$는 평균적으로 주어진 설명변수 값에 대해 가장 가능성이 높은 클래스에 각 관측치를 할당하는 매우 단순한 분류기에 의해 그 값이 최소가 된다는 것을 보여줄 수 있다. (증명은 생략) <br>
다시 말해, 설명변수 벡터 $x_0$를 가지는 test value는 단순히 다음식이 가장 큰 클래스 $j$에 할당되어야 한다.

$$
\textrm{Pr}(Y=j | X=x_0)
$$

즉 $x_0$가 주어졌을 때 $Y=j$일 조건부 확률이 가장 큰 class로 분류한다. <br>
이 단순한 분류기를 **베이즈 분류기** 라고 한다.

<br>

<p align="center">
	<img src="https://user-images.githubusercontent.com/86343664/132125976-806289e7-050c-405b-8cdd-8be6eba12e1c.png" width="70%" height="70%"/>
</p>

<br>

binary class 예시를 생각해보자. <br>
베이즈 분류기는 $\textrm{Pr}(Y=orange | X=x_0) > 0.5$ 이면 클래스 1, 아니면 클래스 2를 예측하는 문제가 된다. <br>
보라색 선은 이 조건부확률이 정확하게 50%인 점들을 나타내며, 이것을 **베이즈 결정경계(Bayes decision boundary)** 라고 한다.

<br>

베이즈 분류기는 항상 조건부확률이 최대가 되는 클래스를 선택하므로 $X=x_0$에서 오차율은 $1-\max_{j} \textrm{Pr} (Y=j|X=X_0)$일 것이다. <br>
전체 베이즈 오차율 가능한 모든 $X$에 대한 확률을 평균한 것으로 다음 식과 같다.

$$
1-E ( \, \max_{j} \textrm{Pr} (Y=j|X) \, )
$$

<br>

2. K-최근접 이웃 (K-Nearest Neighbors)

이론상 질적 반응변수는 베이즈 분류기를 사용하여 예측하는 것이 항상 가장 좋다. <br>
그러나, 실제 데이터에서는 주어진 $X$에 대한 $Y$의 조건부분포를 모르므로 베이즈 분류기를 계산할 수 없다. <br>
그러므로, 베이즈 분류기는 다른 방법들을 비교하는 데 사용되는 달성할 수 없는 표준 역할을 한다. <br>

베이즈 분류기의 아이디어를 사용하는 다른 방법 중 하나는 **KNN 분류기**이다. <br>
양의 정수 $K$와 test point $x_0$에 대해 먼저 training data에서 $x_0$와 가장 가까운 $K$개 점($N_0$)을 찾아낸다. <br>
그 다음, 클래스 $j$에 대한 조건부확률을 반응변수 값이 $j$인 $N_0$ 내 점들의 비율로 추정한다.

$$
\textrm{Pr} (Y=j|X=x_0) = \frac{1}{K} \sum_{i\in N_0} I(y_i \neq j)
$$

마지막으로 베이즈 정리를 이용해 test point $x_0$를 확률이 가장 높은 클래스에 할당한다.

<br>


<p align="center">
	<img src="https://user-images.githubusercontent.com/86343664/132125978-9ee689a5-0271-417a-8692-0cbf9b058f0b.png">
</p>

<br>

예시를 통해 적용해보자. <br>
왼쪽 패널은 6개의 파란색 관측치와 6개의 주황색 관측치로 구성된 training data를 나타낸다. <br>
검은색 X 표시가 된 관측치에 대해 예측하는 것이 목적이다. <br>
X 표시된 점의 이웃은 원형으로 표시되고, 여기에 2개의 파란색 점과 1개의 주황색 점이 포함되어 있다. <br>
파란색 클래스 추정확률은 2/3 이고 주황색 클래스는 1/3 이다. <br>
따라서 KNN은 X- 표시된 점을 파란색 클래스에 속하는 것으로 예측한다.
오른쪽 패널은 $K$=3인 KNN 기법을 모든 $X1$과 $X2$에 적용하여 대응하는 KNN 결정경계를 나타낸다. <br>
아주 단순한 방법이지만 KNN은 보통 최적의 베이즈 분류기만큼 좋은 성능을 가질 수 있다.

<br>

![2021-09-05-17-12-20](https://user-images.githubusercontent.com/86343664/132125979-9a48394c-34a6-404e-b01e-c1979e8736d4.png)



<br>

$K$의 선택은 KNN 분류기 결과에 큰 영향을 미친다. <br>
위의 그림은 $K$=1과 $K$=100을 사용한 두 가지 KNN 적합을 나타낸다. <br>
$K$=1일 때, 결정경계는 지나치게 유연하고 베이즈 결정경계(보라색)와 맞지 않는 데이터 패턴이 있다. <br>
이것은 편향은 낮지만 분산이 높은 분류기에 해당한다. <br> 
$K$가 증가할수록 결정경계는 덜 유연해지고, 선형에 가까운 결정경계를 제공한다. <br>
이것은 분산은 낮지만 편향이 높은 분류기에 해당한다. <br>
이 자료에서는 $K$=1 과 $K$=100 둘 중 어느 것을 사용해도 예측결과는 좋지 않다.

<br>


> 마무리 

회귀와 분류 설정에서 올바른 수준의 유연성을 선택하는 것은 통계적 학습 방법의 성공에 아주 중요하다. <br>
bias-variance trade-off와 test error의 U-shape는 유연성의 수준을 선택하는 것을 어렵게 만든다. <br>
앞으로는 test error를 추정하여 주어진 방법에 대해 최적의 유연성 수준을 선택하는 다양한 방법들을 배운다. 








