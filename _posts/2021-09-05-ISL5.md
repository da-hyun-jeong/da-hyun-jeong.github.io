---
title: Chap5. Resampling
excerpt: ISL 
toc: true
toc_sticky: true

author_profile: false

date: 2021-09-06 21:15:00 -0000
categories: 
  - ISL 
tags:
  - Machine Learning
---

<br>

재표본추출(Resampling) 방법은 training set에서 반복적으로 표본을 추출하여 모델을 적합함으로써 추가적인 정보를 얻는 것을 말한다. <br>
원래의 표본을 사용해서 모델 적합을 한 번만 하는 경우 얻을 수 없었던 정보들을 얻을 수 있다. <br>
재표본추출은 크게 교차검증( $cross-validation$ )과 부스트랩( $bootstrap$ )이 있다. <br>
교차검증은 test error를 추정하여 모델의 성능을 평가하거나 적절한 수준의 유연성을 선택하는데 사용된다. <br>
부스트랩은 일반적으로 추정의 정확도를 측정하는 데 사용된다. 

<br>
<br>

# 1. 교차검증(Cross-Validaition) 

우리에게 주어진 test set이 있다면 test error rate을 쉽게 계산할 수 있겠지만, 그렇지 않은 경우가 대부분이므로 주어진 training set을 이용하여 목표값을 구하는 방법을 알아보자. 

> LOOCV(Leave-One-Out Cross-Validation)

하나의 관측치 $(x_1, y_1)$이 validation set으로 사용되고 나머지 관측치 $\{(x_2,y_2),...,(x_n, y_n)\}$은 training set으로 구성한다. <br>
$(x_1, y_1)$은 적합에 사용되지 않으므로 거의 편향되지 않은 추정치를 제공한다.<br>
이 절차를 각 $n$개에 대해 반복적으로 시행하고 $n$개의 MSE를 평균한다.

$$
(regression) \quad CV_n = \frac{1}{n}\sum_{i=1}^n MSE_i \\
(classification) \quad CV_n = \frac{1}{n}\sum_{i=1}^n I(y_i \neq \hat{y}_i)
$$

<br>

> k-fold CV

데이터를 임의로 $k$개로 분할하고 첫 번째 fold는 validation set으로 취급하고 나머지 ($k$-1)개의 fold로 모델을 적합한다. <br>
이것도 fold 마다 반복적으로 수행하고, 구해진 MSE를 평균한다.

$$
(regression) \quad CV_k = \frac{1}{k}\sum_{i=1}^k MSE_i \\
(classification) \quad CV_k = \frac{1}{k}\sum_{i=1}^k I(y_i \neq \hat{y}_i)
$$

k-fold CV는 LOOCV 보다 계산량이 적고, 무엇보다 LOOCV 보다 test error rate를 더 정확하게 추정한다는 장점이 있다. <br>
이는 $bias-variance \; trade-off$ 와 관련이 있다.<br>

- bias 관점 : LOOCV는 각각의 훈련셋이 전체 데이터셋의 관측치 수와 거의 같은 (n-1)개의 관측치를 포함하므로 거의 편향되지 않은 추정치를 제공한다. 반면 k-fold CV는 이보다 약간 편향이 높을 것이다.

- variance 관점 : LOOCV는 n개의 적합된 모델의 결과를 평균하는데, 이 각각은 거의 동일한 관측치들로 구성되어 있으므로 서로 높은 상관관계가 있다. 반면 k-fold CV는 각 모델의 training set 사이에 겹치는 부분이 적어 적합된 모델의 결과들은 비교적 상관관계가 낮다. 즉, LOOCV의 test error rate 추정치는 k-foid CV의 추정치보다 분산이 더 큰 경향이 있다.

요약하면 k-fold CV는 k값의 선택에 따라 편향, 분산의 tradeoff 관계가 존재한다. <br>
일반적으로 k=5, k=10 을 사용하면 편향과 분산으로 인한 큰 문제없이 결과를 얻을 수 있다는 것이 경험적으로 알려져 있다.



























